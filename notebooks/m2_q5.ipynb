{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76dd60d2-97c1-4415-9531-c7ce20cd2e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "936f41d6-64f2-4f81-b38f-ded4fbf923ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset():\n",
    "\n",
    "    # Read CSV files\n",
    "    dataset = pd.read_csv('/Users/xiaoxinzhou/Documents/IFT6758_M2_CSV_data/all_data.csv')\n",
    "\n",
    "    # Separate features and labels \n",
    "    X = dataset[['eventIdx', 'game_id', 'Distance from Net',\n",
    "                'Angle from Net', 'Is Net Empty']]\n",
    "    y = dataset[['Is Goal']]\n",
    "\n",
    "    return X,y\n",
    "\n",
    "def train(X, y, features=['Distance from Net']):\n",
    "    '''\n",
    "    reference: https://machinelearningmastery.com/develop-first-xgboost-model-python-scikit-learn/\n",
    "    '''\n",
    "    \n",
    "    X,y = read_dataset()\n",
    "\n",
    "    # Create a training and validation split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X[features],\n",
    "                                                        y,\n",
    "                                                        test_size=0.20,\n",
    "                                                        random_state=50)\n",
    "\n",
    "    # Fit model no training data\n",
    "    model = xgb.XGBClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions for test data\n",
    "    y_pred = model.predict(X_test)\n",
    "    predictions = [round(value) for value in y_pred]\n",
    "\n",
    "    # Evaluate predictions\n",
    "    accuracy = metrics.accuracy_score(y_test, predictions)\n",
    "    print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "885e73f1-1796-4486-aa59-76c8f73cc66e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniforge/base/envs/ift6758-conda-env/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/Caskroom/miniforge/base/envs/ift6758-conda-env/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/Caskroom/miniforge/base/envs/ift6758-conda-env/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:04:07] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1634712680264/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy: 90.39%\n"
     ]
    }
   ],
   "source": [
    "X,y = read_dataset()\n",
    "train(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07bf559e-150b-4bec-ae10-c69acf0450d7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniforge/base/envs/ift6758-conda-env/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/usr/local/Caskroom/miniforge/base/envs/ift6758-conda-env/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/usr/local/Caskroom/miniforge/base/envs/ift6758-conda-env/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:04:32] WARNING: /Users/runner/miniforge3/conda-bld/xgboost-split_1634712680264/work/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy: 90.40%\n"
     ]
    }
   ],
   "source": [
    "train(X,y, features=['Angle from Net'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b4cb11c-af66-411a-a453-aae30afd0929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 90.39%\n"
     ]
    }
   ],
   "source": [
    "# Calculate probability\n",
    "def get_prob(X, y, features=['Distance from Net']):\n",
    "    '''\n",
    "     Calculate the probability.\n",
    "     In X_test_pred_proba, the first column is label 0, the second one is label 1.  \n",
    "    '''\n",
    "    # Create a training and validation split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X[features],y,test_size=0.20,random_state=50)\n",
    "\n",
    "    # Fit model no training data\n",
    "    model = xgb.XGBClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Make predictions for test data\n",
    "    y_pred = model.predict(X_test)\n",
    "    predictions = [round(value) for value in y_pred]        \n",
    "\n",
    "    # Predict the probability\n",
    "    X_test_pred_proba = clf.predict_proba(X_test)\n",
    "\n",
    "    # print(f'The probabilities on validation set is\\n {X_test_pred_proba}')\n",
    "    \n",
    "    return X_test_pred_proba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6e4986-dcea-45f4-ad38-f97227a1d32b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
