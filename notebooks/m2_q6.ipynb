{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "510e3b14-1345-484e-ab56-61f99c0c0401",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ift6758/data/milestone2/q3_baseline\n",
    "import sys\n",
    "sys.path.append('../ift6758/data/milestone2')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ca00183-8ef2-4c29-ba6d-f71c78ec0fbb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'q6_plot'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/r1/g6g5ylnd3l5fdc1tyq1k0v4c0000gn/T/ipykernel_20825/3754956270.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mq6_plot\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mread_all_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m                         \u001b[0mplot_models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'q6_plot'"
     ]
    }
   ],
   "source": [
    "from q6_plot import read_all_features,\\\n",
    "                        plot_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "864a003c-7c7a-4f0f-87f6-0834bee4a951",
   "metadata": {},
   "outputs": [],
   "source": [
    "# part 3 - q1 we got 90.39%, \n",
    "# part 5.2 got 91.27%\n",
    "# part 6 needs to be greater than 90.39%.\n",
    "# part 6 should be better than the untuned baselines, \n",
    "# but it doesn't need to be better than what you get feature selection/hyperparameter tuning.\n",
    "\n",
    "# Approach 1: Decision Tree/MLPClassifier?\n",
    "# Approach 2: Hyperparameter Tuning for Decision Tree/MLPClassifier?\n",
    "    # https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html#sklearn.model_selection.RandomizedSearchCV\n",
    "# Approach 3: More advanced feature selection strategies (PCA?) https://machinelearningmastery.com/feature-selection-machine-learning-python/\n",
    "# Approach 4: Combine approaches 1-3?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d257b2f-5526-453e-a7bc-49e4626e7350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = pd.read_csv('/Users/xiaoxinzhou/Documents/IFT6758_M2_CSV_data/all_data_categorical.csv')\n",
    "dataset = pd.read_csv('/Users/sunjiaao/Courses/IFT6758/m2_CSV_data/all_data_q4_categorical.csv')\n",
    "\n",
    "X = dataset.iloc[: , :-1]\n",
    "y = dataset[['Is Goal']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cabd343d-3369-48ef-90b6-c06419af1104",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################################\n",
    "# Approach 1: Decision Tree Classifier\n",
    "##############################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c6666610-d821-4480-b71a-6fb12c1befc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 84.39%\n",
      "roc_auc: 0.5681074764127346\n"
     ]
    }
   ],
   "source": [
    "def approach_1(X, y):\n",
    "    # Create a training and validation split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                        y,\n",
    "                                                        test_size=0.20,\n",
    "                                                        random_state=50)    \n",
    "    \n",
    "    clf = DecisionTreeClassifier(\n",
    "                        # max_leaf_nodes=3, \n",
    "                        # max_depth=30,\n",
    "                        # random_state=0\n",
    "    )\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))  \n",
    "    \n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "    roc_auc = auc(false_positive_rate, true_positive_rate)    \n",
    "    print(f\"roc_auc: {roc_auc}\")\n",
    "    \n",
    "approach_1(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "4c91bdc8-d10c-487a-ad1d-e37c2bd09235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV 1/5] END max_depth=48, max_features=4, max_leaf_nodes=2, min_samples_leaf=0.1, min_samples_split=0.9, splitter=best;, score=0.908 total time=   0.1s\n",
      "[CV 2/5] END max_depth=48, max_features=4, max_leaf_nodes=2, min_samples_leaf=0.1, min_samples_split=0.9, splitter=best;, score=0.908 total time=   0.1s\n",
      "[CV 3/5] END max_depth=48, max_features=4, max_leaf_nodes=2, min_samples_leaf=0.1, min_samples_split=0.9, splitter=best;, score=0.908 total time=   0.1s\n",
      "[CV 4/5] END max_depth=48, max_features=4, max_leaf_nodes=2, min_samples_leaf=0.1, min_samples_split=0.9, splitter=best;, score=0.908 total time=   0.0s\n",
      "[CV 5/5] END max_depth=48, max_features=4, max_leaf_nodes=2, min_samples_leaf=0.1, min_samples_split=0.9, splitter=best;, score=0.908 total time=   0.1s\n",
      "[CV 1/5] END max_depth=13, max_features=9, max_leaf_nodes=9, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, splitter=best;, score=0.908 total time=   0.2s\n",
      "[CV 2/5] END max_depth=13, max_features=9, max_leaf_nodes=9, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, splitter=best;, score=0.908 total time=   0.2s\n",
      "[CV 3/5] END max_depth=13, max_features=9, max_leaf_nodes=9, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, splitter=best;, score=0.908 total time=   0.2s\n",
      "[CV 4/5] END max_depth=13, max_features=9, max_leaf_nodes=9, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, splitter=best;, score=0.908 total time=   0.2s\n",
      "[CV 5/5] END max_depth=13, max_features=9, max_leaf_nodes=9, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, splitter=best;, score=0.908 total time=   0.2s\n",
      "[CV 1/5] END max_depth=29, max_features=3, max_leaf_nodes=4, min_samples_leaf=0.5, min_samples_split=1.0, splitter=random;, score=0.908 total time=   0.0s\n",
      "[CV 2/5] END max_depth=29, max_features=3, max_leaf_nodes=4, min_samples_leaf=0.5, min_samples_split=1.0, splitter=random;, score=0.908 total time=   0.0s\n",
      "[CV 3/5] END max_depth=29, max_features=3, max_leaf_nodes=4, min_samples_leaf=0.5, min_samples_split=1.0, splitter=random;, score=0.908 total time=   0.0s\n",
      "[CV 4/5] END max_depth=29, max_features=3, max_leaf_nodes=4, min_samples_leaf=0.5, min_samples_split=1.0, splitter=random;, score=0.908 total time=   0.0s\n",
      "[CV 5/5] END max_depth=29, max_features=3, max_leaf_nodes=4, min_samples_leaf=0.5, min_samples_split=1.0, splitter=random;, score=0.908 total time=   0.0s\n",
      "[CV 1/5] END max_depth=19, max_features=6, max_leaf_nodes=3, min_samples_leaf=0.1, min_samples_split=0.5, splitter=random;, score=0.908 total time=   0.0s\n",
      "[CV 2/5] END max_depth=19, max_features=6, max_leaf_nodes=3, min_samples_leaf=0.1, min_samples_split=0.5, splitter=random;, score=0.908 total time=   0.0s\n",
      "[CV 3/5] END max_depth=19, max_features=6, max_leaf_nodes=3, min_samples_leaf=0.1, min_samples_split=0.5, splitter=random;, score=0.908 total time=   0.0s\n",
      "[CV 4/5] END max_depth=19, max_features=6, max_leaf_nodes=3, min_samples_leaf=0.1, min_samples_split=0.5, splitter=random;, score=0.908 total time=   0.0s\n",
      "[CV 5/5] END max_depth=19, max_features=6, max_leaf_nodes=3, min_samples_leaf=0.1, min_samples_split=0.5, splitter=random;, score=0.908 total time=   0.0s\n",
      "[CV 1/5] END max_depth=38, max_features=6, max_leaf_nodes=9, min_samples_leaf=0.1, min_samples_split=0.2, splitter=best;, score=0.908 total time=   0.2s\n",
      "[CV 2/5] END max_depth=38, max_features=6, max_leaf_nodes=9, min_samples_leaf=0.1, min_samples_split=0.2, splitter=best;, score=0.908 total time=   0.2s\n",
      "[CV 3/5] END max_depth=38, max_features=6, max_leaf_nodes=9, min_samples_leaf=0.1, min_samples_split=0.2, splitter=best;, score=0.908 total time=   0.2s\n",
      "[CV 4/5] END max_depth=38, max_features=6, max_leaf_nodes=9, min_samples_leaf=0.1, min_samples_split=0.2, splitter=best;, score=0.908 total time=   0.2s\n",
      "[CV 5/5] END max_depth=38, max_features=6, max_leaf_nodes=9, min_samples_leaf=0.1, min_samples_split=0.2, splitter=best;, score=0.908 total time=   0.2s\n",
      "[CV 1/5] END max_depth=45, max_features=9, max_leaf_nodes=5, min_samples_leaf=0.30000000000000004, min_samples_split=0.9, splitter=best;, score=0.908 total time=   0.1s\n",
      "[CV 2/5] END max_depth=45, max_features=9, max_leaf_nodes=5, min_samples_leaf=0.30000000000000004, min_samples_split=0.9, splitter=best;, score=0.908 total time=   0.1s\n",
      "[CV 3/5] END max_depth=45, max_features=9, max_leaf_nodes=5, min_samples_leaf=0.30000000000000004, min_samples_split=0.9, splitter=best;, score=0.908 total time=   0.1s\n",
      "[CV 4/5] END max_depth=45, max_features=9, max_leaf_nodes=5, min_samples_leaf=0.30000000000000004, min_samples_split=0.9, splitter=best;, score=0.908 total time=   0.1s\n",
      "[CV 5/5] END max_depth=45, max_features=9, max_leaf_nodes=5, min_samples_leaf=0.30000000000000004, min_samples_split=0.9, splitter=best;, score=0.908 total time=   0.1s\n",
      "[CV 1/5] END max_depth=38, max_features=1, max_leaf_nodes=9, min_samples_leaf=0.1, min_samples_split=0.6, splitter=best;, score=0.908 total time=   0.1s\n",
      "[CV 2/5] END max_depth=38, max_features=1, max_leaf_nodes=9, min_samples_leaf=0.1, min_samples_split=0.6, splitter=best;, score=0.908 total time=   0.0s\n",
      "[CV 3/5] END max_depth=38, max_features=1, max_leaf_nodes=9, min_samples_leaf=0.1, min_samples_split=0.6, splitter=best;, score=0.908 total time=   0.0s\n",
      "[CV 4/5] END max_depth=38, max_features=1, max_leaf_nodes=9, min_samples_leaf=0.1, min_samples_split=0.6, splitter=best;, score=0.908 total time=   0.0s\n",
      "[CV 5/5] END max_depth=38, max_features=1, max_leaf_nodes=9, min_samples_leaf=0.1, min_samples_split=0.6, splitter=best;, score=0.908 total time=   0.0s\n",
      "[CV 1/5] END max_depth=23, max_features=3, max_leaf_nodes=2, min_samples_leaf=0.4, min_samples_split=0.2, splitter=random;, score=0.908 total time=   0.0s\n",
      "[CV 2/5] END max_depth=23, max_features=3, max_leaf_nodes=2, min_samples_leaf=0.4, min_samples_split=0.2, splitter=random;, score=0.908 total time=   0.0s\n",
      "[CV 3/5] END max_depth=23, max_features=3, max_leaf_nodes=2, min_samples_leaf=0.4, min_samples_split=0.2, splitter=random;, score=0.908 total time=   0.0s\n",
      "[CV 4/5] END max_depth=23, max_features=3, max_leaf_nodes=2, min_samples_leaf=0.4, min_samples_split=0.2, splitter=random;, score=0.908 total time=   0.0s\n",
      "[CV 5/5] END max_depth=23, max_features=3, max_leaf_nodes=2, min_samples_leaf=0.4, min_samples_split=0.2, splitter=random;, score=0.908 total time=   0.0s\n",
      "[CV 1/5] END max_depth=45, max_features=8, max_leaf_nodes=4, min_samples_leaf=0.30000000000000004, min_samples_split=0.6, splitter=best;, score=0.908 total time=   0.1s\n",
      "[CV 2/5] END max_depth=45, max_features=8, max_leaf_nodes=4, min_samples_leaf=0.30000000000000004, min_samples_split=0.6, splitter=best;, score=0.908 total time=   0.1s\n",
      "[CV 3/5] END max_depth=45, max_features=8, max_leaf_nodes=4, min_samples_leaf=0.30000000000000004, min_samples_split=0.6, splitter=best;, score=0.908 total time=   0.1s\n",
      "[CV 4/5] END max_depth=45, max_features=8, max_leaf_nodes=4, min_samples_leaf=0.30000000000000004, min_samples_split=0.6, splitter=best;, score=0.908 total time=   0.1s\n",
      "[CV 5/5] END max_depth=45, max_features=8, max_leaf_nodes=4, min_samples_leaf=0.30000000000000004, min_samples_split=0.6, splitter=best;, score=0.908 total time=   0.1s\n",
      "[CV 1/5] END max_depth=20, max_features=10, max_leaf_nodes=5, min_samples_leaf=0.30000000000000004, min_samples_split=1.0, splitter=random;, score=0.908 total time=   0.0s\n",
      "[CV 2/5] END max_depth=20, max_features=10, max_leaf_nodes=5, min_samples_leaf=0.30000000000000004, min_samples_split=1.0, splitter=random;, score=0.908 total time=   0.0s\n",
      "[CV 3/5] END max_depth=20, max_features=10, max_leaf_nodes=5, min_samples_leaf=0.30000000000000004, min_samples_split=1.0, splitter=random;, score=0.908 total time=   0.0s\n",
      "[CV 4/5] END max_depth=20, max_features=10, max_leaf_nodes=5, min_samples_leaf=0.30000000000000004, min_samples_split=1.0, splitter=random;, score=0.908 total time=   0.0s\n",
      "[CV 5/5] END max_depth=20, max_features=10, max_leaf_nodes=5, min_samples_leaf=0.30000000000000004, min_samples_split=1.0, splitter=random;, score=0.908 total time=   0.0s\n",
      "{'splitter': 'best', 'min_samples_split': 0.9, 'min_samples_leaf': 0.1, 'max_leaf_nodes': 2, 'max_features': 4, 'max_depth': 48}\n",
      "Accuracy: 90.82%\n",
      "roc_auc: 0.5\n"
     ]
    }
   ],
   "source": [
    "###################################################################################################\n",
    "# Approach 2: Decision Tree Classifier with Randomized search on hyper parameters and Regularization\n",
    "###################################################################################################\n",
    "\n",
    "from scipy.stats import randint\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "\n",
    "def approach_2(X, y):\n",
    "    # Create a training and validation split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                        y,\n",
    "                                                        test_size=0.20,\n",
    "                                                        random_state=50)    \n",
    "    \n",
    "    dtc = DecisionTreeClassifier()\n",
    "    \n",
    "    # https://machinelearningmastery.com/hyperparameter-optimization-with-random-search-and-grid-search/\n",
    "    \n",
    "    space = dict()\n",
    "    space['splitter'] = ['best', 'random']\n",
    "    space['max_depth'] = list(range(2, 50)) #np.linspace(1, 32, 32, endpoint=True) #randint(10, 50)\n",
    "    space['min_samples_split'] = np.linspace(0.1, 1.0, 10, endpoint=True)\n",
    "    space['min_samples_leaf'] = np.linspace(0.1, 0.5, 5, endpoint=True)\n",
    "    space['max_features'] = list(range(1, X_train.shape[1]))\n",
    "    space['max_leaf_nodes'] = list(range(2, 10))\n",
    "    \n",
    "    clf = RandomizedSearchCV(dtc, space, random_state=50, verbose=3)\n",
    "    \n",
    "    search = clf.fit(X_train, y_train)\n",
    "    print(search.best_params_)\n",
    "    y_pred = search.predict(X_test)\n",
    "    \n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))  \n",
    "    \n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "    roc_auc = auc(false_positive_rate, true_positive_rate)    \n",
    "    print(f\"roc_auc: {roc_auc}\")\n",
    "    \n",
    "approach_2(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "6007be0c-ca72-401c-8b82-76af313284ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(226136, 12)\n",
      "        X-Coordinate  Y-Coordinate  Shot Distance  Shot Angle  Shot Type  \\\n",
      "160597           -32           -25      62.241465  113.682088          0   \n",
      "156619           -45            15      46.486557   71.175290          0   \n",
      "253246           -40           -11      50.219518  102.652557          2   \n",
      "88000             57           -19      37.215588   59.300277          0   \n",
      "10516            -62           -12      29.546573  113.962489          0   \n",
      "...              ...           ...            ...         ...        ...   \n",
      "165959            72             4      17.464249  103.240520          0   \n",
      "186463            57            12      34.176015  110.556045          0   \n",
      "153709            61             6      28.635642  102.094757          0   \n",
      "239499            72           -11      89.988888    0.000000          1   \n",
      "103904            80            -1       9.055385   83.659808          0   \n",
      "\n",
      "        Was Net Empty  Last Event Type  Last X-Coordinate  Last Y-Coordinate  \\\n",
      "160597              0                1                -69                -22   \n",
      "156619              0                2                  2                -14   \n",
      "253246              0                1                 20                 22   \n",
      "88000               0                5                -71                  7   \n",
      "10516               0                0                -32                -41   \n",
      "...               ...              ...                ...                ...   \n",
      "165959              0                4                 44                 -1   \n",
      "186463              0                4                 -5                 12   \n",
      "153709              0                6                 59                  7   \n",
      "239499              0                2                -50                -39   \n",
      "103904              0                6                 37                 30   \n",
      "\n",
      "        Time from Last Event (seconds)  Distance from Last Event     Speed  \n",
      "160597                              26                 37.121422  1.427747  \n",
      "156619                              10                 55.226805  5.522681  \n",
      "253246                              10                 68.476273  6.847627  \n",
      "88000                               25                130.613935  5.224557  \n",
      "10516                               31                 41.725292  1.345977  \n",
      "...                                ...                       ...       ...  \n",
      "165959                               4                 28.442925  7.110731  \n",
      "186463                              14                 62.000000  4.428571  \n",
      "153709                              13                  2.236068  0.172005  \n",
      "239499                              44                125.171882  2.844815  \n",
      "103904                              55                 53.009433  0.963808  \n",
      "\n",
      "[226136 rows x 12 columns]\n",
      "(226136, 3)\n",
      "[[ 73.18860366 -21.60647238 -24.72691092]\n",
      " [ 28.68795041  34.22714809  -7.93676293]\n",
      " [ 12.38228177  43.56337112   5.4406313 ]\n",
      " ...\n",
      " [-84.24480373  -5.90689941 -60.56099506]\n",
      " [-11.61131313 -89.1309111   64.73594532]\n",
      " [-80.78782186 -34.96037638  -7.18683771]]\n",
      "Accuracy: 82.86%\n",
      "roc_auc: 0.5137854191879555\n"
     ]
    }
   ],
   "source": [
    "####################################################################################\n",
    "# Approach 3: Decision Tree Classifier with PCA Feature Reduction\n",
    "####################################################################################\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "def approach_3(X, y):\n",
    "#     dataset = pd.read_csv('/Users/sunjiaao/Courses/IFT6758/m2_CSV_data/all_data_q4_categorical.csv')\n",
    "\n",
    "#     X = dataset[['X-Coordinate', 'Y-Coordinate',\n",
    "#              'Shot Distance', 'Shot Angle', \n",
    "#              'Shot Type', \n",
    "#              'Was Net Empty', \n",
    "#              'Last Event Type', \n",
    "#              'Last X-Coordinate', 'Last Y-Coordinate', \n",
    "#              'Time from Last Event (seconds)', \n",
    "#              'Distance from Last Event', \n",
    "#              'Is Rebound',\n",
    "#              'Change in Shot Angle', \n",
    "#              'Speed'\n",
    "#             ]]\n",
    "    \n",
    "#     y = dataset[['Is Goal']]\n",
    "    \n",
    "    # Create a training and validation split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                        y,\n",
    "                                                        test_size=0.20,\n",
    "                                                        random_state=50)    \n",
    "    \n",
    "    print(X_train.shape)\n",
    "    print(X_train)\n",
    "    pca = PCA(n_components=3)\n",
    "    X_train_transformed = pca.fit_transform(X_train)\n",
    "    \n",
    "    print(X_train_transformed.shape)\n",
    "    print(X_train_transformed)\n",
    "    \n",
    "    clf = DecisionTreeClassifier(\n",
    "                        # max_leaf_nodes=3, \n",
    "                        # max_depth=30,\n",
    "                        # random_state=0\n",
    "    )\n",
    "    \n",
    "    clf.fit(X_train_transformed, y_train)\n",
    "    \n",
    "    X_test_transformed = pca.fit_transform(X_test)\n",
    "    \n",
    "    y_pred = clf.predict(X_test_transformed)\n",
    "    \n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))  \n",
    "    \n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "    roc_auc = auc(false_positive_rate, true_positive_rate)    \n",
    "    print(f\"roc_auc: {roc_auc}\")\n",
    "    \n",
    "approach_3(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "14186bf9-020c-4131-b08b-baa29c983c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "[CV 1/5] END max_depth=48, max_features=4, max_leaf_nodes=2, min_samples_leaf=0.1, min_samples_split=0.9, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 2/5] END max_depth=48, max_features=4, max_leaf_nodes=2, min_samples_leaf=0.1, min_samples_split=0.9, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 3/5] END max_depth=48, max_features=4, max_leaf_nodes=2, min_samples_leaf=0.1, min_samples_split=0.9, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 4/5] END max_depth=48, max_features=4, max_leaf_nodes=2, min_samples_leaf=0.1, min_samples_split=0.9, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 5/5] END max_depth=48, max_features=4, max_leaf_nodes=2, min_samples_leaf=0.1, min_samples_split=0.9, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 1/5] END max_depth=13, max_features=9, max_leaf_nodes=9, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 2/5] END max_depth=13, max_features=9, max_leaf_nodes=9, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 3/5] END max_depth=13, max_features=9, max_leaf_nodes=9, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 4/5] END max_depth=13, max_features=9, max_leaf_nodes=9, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 5/5] END max_depth=13, max_features=9, max_leaf_nodes=9, min_samples_leaf=0.1, min_samples_split=0.30000000000000004, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 1/5] END max_depth=29, max_features=3, max_leaf_nodes=4, min_samples_leaf=0.5, min_samples_split=1.0, splitter=random;, score=0.908 total time=   0.0s\n",
      "[CV 2/5] END max_depth=29, max_features=3, max_leaf_nodes=4, min_samples_leaf=0.5, min_samples_split=1.0, splitter=random;, score=0.908 total time=   0.0s\n",
      "[CV 3/5] END max_depth=29, max_features=3, max_leaf_nodes=4, min_samples_leaf=0.5, min_samples_split=1.0, splitter=random;, score=0.908 total time=   0.0s\n",
      "[CV 4/5] END max_depth=29, max_features=3, max_leaf_nodes=4, min_samples_leaf=0.5, min_samples_split=1.0, splitter=random;, score=0.908 total time=   0.0s\n",
      "[CV 5/5] END max_depth=29, max_features=3, max_leaf_nodes=4, min_samples_leaf=0.5, min_samples_split=1.0, splitter=random;, score=0.908 total time=   0.0s\n",
      "[CV 1/5] END max_depth=19, max_features=6, max_leaf_nodes=3, min_samples_leaf=0.1, min_samples_split=0.5, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 2/5] END max_depth=19, max_features=6, max_leaf_nodes=3, min_samples_leaf=0.1, min_samples_split=0.5, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 3/5] END max_depth=19, max_features=6, max_leaf_nodes=3, min_samples_leaf=0.1, min_samples_split=0.5, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 4/5] END max_depth=19, max_features=6, max_leaf_nodes=3, min_samples_leaf=0.1, min_samples_split=0.5, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 5/5] END max_depth=19, max_features=6, max_leaf_nodes=3, min_samples_leaf=0.1, min_samples_split=0.5, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 1/5] END max_depth=38, max_features=6, max_leaf_nodes=9, min_samples_leaf=0.1, min_samples_split=0.2, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 2/5] END max_depth=38, max_features=6, max_leaf_nodes=9, min_samples_leaf=0.1, min_samples_split=0.2, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 3/5] END max_depth=38, max_features=6, max_leaf_nodes=9, min_samples_leaf=0.1, min_samples_split=0.2, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 4/5] END max_depth=38, max_features=6, max_leaf_nodes=9, min_samples_leaf=0.1, min_samples_split=0.2, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 5/5] END max_depth=38, max_features=6, max_leaf_nodes=9, min_samples_leaf=0.1, min_samples_split=0.2, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 1/5] END max_depth=45, max_features=9, max_leaf_nodes=5, min_samples_leaf=0.30000000000000004, min_samples_split=0.9, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 2/5] END max_depth=45, max_features=9, max_leaf_nodes=5, min_samples_leaf=0.30000000000000004, min_samples_split=0.9, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 3/5] END max_depth=45, max_features=9, max_leaf_nodes=5, min_samples_leaf=0.30000000000000004, min_samples_split=0.9, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 4/5] END max_depth=45, max_features=9, max_leaf_nodes=5, min_samples_leaf=0.30000000000000004, min_samples_split=0.9, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 5/5] END max_depth=45, max_features=9, max_leaf_nodes=5, min_samples_leaf=0.30000000000000004, min_samples_split=0.9, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 1/5] END max_depth=38, max_features=1, max_leaf_nodes=9, min_samples_leaf=0.1, min_samples_split=0.6, splitter=best;, score=0.908 total time=   0.1s\n",
      "[CV 2/5] END max_depth=38, max_features=1, max_leaf_nodes=9, min_samples_leaf=0.1, min_samples_split=0.6, splitter=best;, score=0.908 total time=   0.0s\n",
      "[CV 3/5] END max_depth=38, max_features=1, max_leaf_nodes=9, min_samples_leaf=0.1, min_samples_split=0.6, splitter=best;, score=0.908 total time=   0.1s\n",
      "[CV 4/5] END max_depth=38, max_features=1, max_leaf_nodes=9, min_samples_leaf=0.1, min_samples_split=0.6, splitter=best;, score=0.908 total time=   0.1s\n",
      "[CV 5/5] END max_depth=38, max_features=1, max_leaf_nodes=9, min_samples_leaf=0.1, min_samples_split=0.6, splitter=best;, score=0.908 total time=   0.1s\n",
      "[CV 1/5] END max_depth=23, max_features=3, max_leaf_nodes=2, min_samples_leaf=0.4, min_samples_split=0.2, splitter=random;, score=0.908 total time=   0.0s\n",
      "[CV 2/5] END max_depth=23, max_features=3, max_leaf_nodes=2, min_samples_leaf=0.4, min_samples_split=0.2, splitter=random;, score=0.908 total time=   0.0s\n",
      "[CV 3/5] END max_depth=23, max_features=3, max_leaf_nodes=2, min_samples_leaf=0.4, min_samples_split=0.2, splitter=random;, score=0.908 total time=   0.0s\n",
      "[CV 4/5] END max_depth=23, max_features=3, max_leaf_nodes=2, min_samples_leaf=0.4, min_samples_split=0.2, splitter=random;, score=0.908 total time=   0.0s\n",
      "[CV 5/5] END max_depth=23, max_features=3, max_leaf_nodes=2, min_samples_leaf=0.4, min_samples_split=0.2, splitter=random;, score=0.908 total time=   0.0s\n",
      "[CV 1/5] END max_depth=45, max_features=8, max_leaf_nodes=4, min_samples_leaf=0.30000000000000004, min_samples_split=0.6, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 2/5] END max_depth=45, max_features=8, max_leaf_nodes=4, min_samples_leaf=0.30000000000000004, min_samples_split=0.6, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 3/5] END max_depth=45, max_features=8, max_leaf_nodes=4, min_samples_leaf=0.30000000000000004, min_samples_split=0.6, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 4/5] END max_depth=45, max_features=8, max_leaf_nodes=4, min_samples_leaf=0.30000000000000004, min_samples_split=0.6, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 5/5] END max_depth=45, max_features=8, max_leaf_nodes=4, min_samples_leaf=0.30000000000000004, min_samples_split=0.6, splitter=best;, score=nan total time=   0.0s\n",
      "[CV 1/5] END max_depth=20, max_features=10, max_leaf_nodes=5, min_samples_leaf=0.30000000000000004, min_samples_split=1.0, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 2/5] END max_depth=20, max_features=10, max_leaf_nodes=5, min_samples_leaf=0.30000000000000004, min_samples_split=1.0, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 3/5] END max_depth=20, max_features=10, max_leaf_nodes=5, min_samples_leaf=0.30000000000000004, min_samples_split=1.0, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 4/5] END max_depth=20, max_features=10, max_leaf_nodes=5, min_samples_leaf=0.30000000000000004, min_samples_split=1.0, splitter=random;, score=nan total time=   0.0s\n",
      "[CV 5/5] END max_depth=20, max_features=10, max_leaf_nodes=5, min_samples_leaf=0.30000000000000004, min_samples_split=1.0, splitter=random;, score=nan total time=   0.0s\n",
      "Accuracy: 90.82%\n",
      "roc_auc: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sunjiaao/opt/anaconda3/envs/ift6758-conda-env/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "35 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "35 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/sunjiaao/opt/anaconda3/envs/ift6758-conda-env/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/sunjiaao/opt/anaconda3/envs/ift6758-conda-env/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"/Users/sunjiaao/opt/anaconda3/envs/ift6758-conda-env/lib/python3.9/site-packages/sklearn/tree/_classes.py\", line 308, in fit\n",
      "    raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "ValueError: max_features must be in (0, n_features]\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/sunjiaao/opt/anaconda3/envs/ift6758-conda-env/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.90779885        nan        nan        nan\n",
      " 0.90779885 0.90779885        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "####################################################################################\n",
    "# Approach 4: Decision Tree Classifier combining approaches 2 and 3\n",
    "####################################################################################\n",
    "\n",
    "def approach_4(X, y):\n",
    "    # Create a training and validation split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                        y,\n",
    "                                                        test_size=0.20,\n",
    "                                                        random_state=50)    \n",
    "    \n",
    "    pca = PCA(n_components=3)\n",
    "    X_train_transformed = pca.fit_transform(X_train)\n",
    "    \n",
    "    dtc = DecisionTreeClassifier()\n",
    "    \n",
    "    # https://machinelearningmastery.com/hyperparameter-optimization-with-random-search-and-grid-search/\n",
    "    \n",
    "    space = dict()\n",
    "    space['splitter'] = ['best', 'random']\n",
    "    space['max_depth'] = list(range(2, 50)) #np.linspace(1, 32, 32, endpoint=True) #randint(10, 50)\n",
    "    space['min_samples_split'] = np.linspace(0.1, 1.0, 10, endpoint=True)\n",
    "    space['min_samples_leaf'] = np.linspace(0.1, 0.5, 5, endpoint=True)\n",
    "    space['max_features'] = list(range(1, X_train.shape[1]))\n",
    "    space['max_leaf_nodes'] = list(range(2, 10))\n",
    "    \n",
    "    clf = RandomizedSearchCV(dtc, space, random_state=50, verbose=3)\n",
    "    \n",
    "    search = clf.fit(X_train_transformed, y_train)\n",
    "    \n",
    "    X_test_transformed = pca.fit_transform(X_test)\n",
    "    \n",
    "    y_pred = search.predict(X_test_transformed)\n",
    "    \n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))  \n",
    "    \n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "    roc_auc = auc(false_positive_rate, true_positive_rate)    \n",
    "    print(f\"roc_auc: {roc_auc}\")\n",
    "    \n",
    "approach_4(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ee3c032b-5644-403e-9f3c-ab00f99e8a54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # ref: https://medium.com/@mohtedibf/indepth-parameter-tuning-for-decision-tree-6753118a03c3\n",
    "# def tree_tune_max_path():\n",
    "    \n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "#                                                         y,\n",
    "#                                                         test_size=0.20,\n",
    "#                                                         random_state=50) \n",
    "    \n",
    "#     max_depths = np.linspace(1, 50, 50, endpoint=True)\n",
    "#     train_results = []\n",
    "#     test_results = []\n",
    "    \n",
    "#     for max_depth in max_depths:\n",
    "#         dt = DecisionTreeClassifier(max_depth=max_depth)\n",
    "#         dt.fit(X_train, y_train)\n",
    "#         train_pred = dt.predict(X_train)\n",
    "        \n",
    "#         false_positive_rate, true_positive_rate, thresholds = roc_curve(y_train, train_pred)\n",
    "#         roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "\n",
    "#         # Add auc score to previous train results\n",
    "#         train_results.append(roc_auc)\n",
    "#         y_pred = dt.predict(X_test)\n",
    "#         false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "#         roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "\n",
    "\n",
    "#         # Add auc score to previous test results\n",
    "#         test_results.append(roc_auc)\n",
    "    \n",
    "#     from matplotlib.legend_handler import HandlerLine2D\n",
    "#     line1, = plt.plot(max_depths, train_results, 'b', label=\"Train AUC\")\n",
    "#     line2, = plt.plot(max_depths, test_results, 'r', label=\"Test AUC\")\n",
    "    \n",
    "#     plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "#     plt.ylabel('AUC score')\n",
    "#     plt.xlabel('Tree depth')\n",
    "#     plt.show()   \n",
    "# tree_tune_max_path()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cee68281-fd32-4fea-ac85-50c45d336a1f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/r1/g6g5ylnd3l5fdc1tyq1k0v4c0000gn/T/ipykernel_20825/3335283383.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'decision_tree'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'plot_models' is not defined"
     ]
    }
   ],
   "source": [
    "plot_models(X,y,'decision_tree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "323082dc-e55c-470f-a61c-b08995cbec2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ##############################################################################\n",
    "# # Approch 2: Regularization: Lasso Regression\n",
    "# # \n",
    "# # ref: https://harish-reddy.medium.com/regularization-in-python-699cfbad8622\n",
    "# ##############################################################################\n",
    "# from sklearn.linear_model import Lasso\n",
    "# from sklearn.metrics import r2_score\n",
    "\n",
    "# def lasso_train(X, y):\n",
    "    \n",
    "#     # Create a training and validation split\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "#                                                         y,\n",
    "#                                                         test_size=0.20,\n",
    "#                                                         random_state=50) \n",
    "    \n",
    "#     lassoreg = Lasso(alpha=0.001, normalize=True)\n",
    "#     lassoreg.fit(X_train, y_train)\n",
    "    \n",
    "#     print(f\"Lasso score: {lassoreg.score(X_test, y_test)}\")\n",
    "    \n",
    "#     # y_pred = lassoreg.predict(X_test)\n",
    "    \n",
    "#     # accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "#     # print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "\n",
    "#     # print(\"R-Square Value\",r2_score(y_test,y_pred))\n",
    "#     # print(\"\\n\")\n",
    "#     # print (\"mean_absolute_error :\",metrics.mean_absolute_error(y_test, y_pred))\n",
    "#     # print(\"\\n\")\n",
    "#     # print (\"mean_squared_error : \",metrics.mean_squared_error(y_test, y_pred))\n",
    "#     # print(\"\\n\")\n",
    "#     # print (\"root_mean_squared_error : \",np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "    \n",
    "# lasso_train(X, y)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7afe96cd-51b4-43a2-8b74-521ac48dd792",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##############################################################################\n",
    "# # Approch 3: Hyperparameter tuning, cross validation strategies \n",
    "# # \n",
    "# # ref: \n",
    "# # - https://scikit-learn.org/stable/modules/cross_validation.html\n",
    "# # - https://www.jeremyjordan.me/hyperparameter-tuning/\n",
    "# # - https://ai.plainenglish.io/hyperparameter-tuning-of-decision-tree-classifier-using-gridsearchcv-2a6ebcaffeda\n",
    "# ##############################################################################\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# def tree2_train(X, y, features=['Distance from Net']):\n",
    "#     # Create a training and validation split\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X[features],\n",
    "#                                                         y,\n",
    "#                                                         test_size=0.20,\n",
    "#                                                         random_state=50)    \n",
    "    \n",
    "#     clf = DecisionTreeClassifier(max_leaf_nodes=3, random_state=0)\n",
    "#     clf.fit(X_train, y_train)\n",
    "    \n",
    "#     # Cross validation with 10 folds\n",
    "#     scores = cross_val_score(clf, X, y, cv=10) \n",
    "#     print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))\n",
    "    \n",
    "#     # Grid search\n",
    "#     param_dict = {\n",
    "#         'criterion': ['gini', 'entropy'],\n",
    "#         'max_depth': range(1, 10),\n",
    "#         'min_samples_split': range(1, 10),\n",
    "#         'min_samples_leaf': range(1, 5)\n",
    "#         }\n",
    "    \n",
    "#     grid = GridSearchCV(clf,\n",
    "#                        param_grid=param_dict,\n",
    "#                        cv=10,\n",
    "#                        verbose=1,\n",
    "#                        n_jobs=-1)\n",
    "    \n",
    "#     grid.fit(X_train, y_train)\n",
    "#     print(f\"grid best params: {grid.best_params_}\")\n",
    "#     print(f\"grid best estimator: {grid.best_estimator_}\")\n",
    "#     print(f\"grid best score: {grid.best_score_}\")\n",
    "    \n",
    "# tree2_train(X, y)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0533aad7-6019-4794-a173-fedee9b9fc33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sunjiaao/opt/anaconda3/envs/ift6758-conda-env/lib/python3.9/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "/Users/sunjiaao/opt/anaconda3/envs/ift6758-conda-env/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/sunjiaao/opt/anaconda3/envs/ift6758-conda-env/lib/python3.9/site-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:16:00] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy: 91.28%\n"
     ]
    }
   ],
   "source": [
    "####################################################################################\n",
    "# Approach 3: Hand Select Feature Selection + Some Existing Feature Selection Method\n",
    "####################################################################################\n",
    "import xgboost as xgb\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "def approach_3(X, y):\n",
    "    # Create a training and validation split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                        y,\n",
    "                                                        test_size=0.20,\n",
    "                                                        random_state=50)    \n",
    "    \n",
    "    clf = DecisionTreeClassifier(\n",
    "                        # max_leaf_nodes=3, \n",
    "                        # max_depth=30,\n",
    "                        # random_state=0\n",
    "    )\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "    print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))  \n",
    "    \n",
    "    false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n",
    "    roc_auc = auc(false_positive_rate, true_positive_rate)    \n",
    "    print(f\"roc_auc: {roc_auc}\")\n",
    "    \n",
    "approach_3(X, y)\n",
    "\n",
    "\n",
    "\n",
    "# Read CSV files\n",
    "dataset = pd.read_csv('/Users/sunjiaao/Courses/IFT6758/m2_CSV_data/all_data_q4_categorical.csv')\n",
    "\n",
    "# Separate features and labels \n",
    "X = dataset[['X-Coordinate', 'Y-Coordinate',\n",
    "             'Shot Distance', 'Shot Angle', \n",
    "             'Shot Type', \n",
    "             'Was Net Empty', \n",
    "             'Last Event Type', \n",
    "             'Last X-Coordinate', 'Last Y-Coordinate', \n",
    "             'Time from Last Event (seconds)', \n",
    "             'Distance from Last Event', \n",
    "             # 'Is Rebound',\n",
    "             # 'Change in Shot Angle', \n",
    "             'Speed'\n",
    "            ]]\n",
    "\n",
    "y = dataset[['Is Goal']]\n",
    "\n",
    "# Create a training and validation split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.20,\n",
    "                                                    random_state=50)\n",
    "\n",
    "model = xgb.XGBClassifier()\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions for test data\n",
    "y_test_pred = model.predict(X_test)\n",
    "y_test = y_test.to_numpy().flatten()\n",
    "\n",
    "# Evaluate predictions\n",
    "accuracy = metrics.accuracy_score(y_test, y_test_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bdd56834-c689-474c-bd10-7be00bfef550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 91.23%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "# Read CSV files\n",
    "dataset = pd.read_csv('/Users/sunjiaao/Courses/IFT6758/m2_CSV_data/all_data_q4_categorical.csv')\n",
    "\n",
    "# # Separate features and labels \n",
    "# X = dataset[['eventIdx', 'game_id', 'Game Seconds', 'Game Period', 'X-Coordinate', 'Y-Coordinate',\n",
    "#            'Shot Distance', 'Shot Angle', 'Shot Type', 'Was Net Empty', 'Last Event Type', 'Last X-Coordinate',\n",
    "#            'Last Y-Coordinate', 'Time from Last Event (seconds)', 'Distance from Last Event', 'Is Rebound',\n",
    "#            'Change in Shot Angle', 'Speed']]\n",
    "\n",
    "# Separate features and labels \n",
    "X = dataset[['X-Coordinate', 'Y-Coordinate',\n",
    "             'Shot Distance', 'Shot Angle', \n",
    "             'Shot Type', \n",
    "             'Was Net Empty', \n",
    "             'Last Event Type', \n",
    "             'Last X-Coordinate', 'Last Y-Coordinate', \n",
    "             'Time from Last Event (seconds)', \n",
    "             'Distance from Last Event', \n",
    "             # 'Is Rebound',\n",
    "             # 'Change in Shot Angle', \n",
    "             'Speed'\n",
    "            ]]\n",
    "\n",
    "y = dataset[['Is Goal']].values.ravel()\n",
    "\n",
    "# Create a training and validation split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size=0.20,\n",
    "                                                    random_state=50)\n",
    "\n",
    "clf = MLPClassifier(hidden_layer_sizes=(8, 8, 8), \n",
    "                    activation='relu',\n",
    "                    solver='adam', \n",
    "                    alpha=1e-5,\n",
    "                    max_iter=200,\n",
    "                    random_state=1\n",
    "                   )\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645c9425-af13-4638-bc63-84aedff52f95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
